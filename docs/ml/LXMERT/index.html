

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>LXMERT:Transformers–Learning Cross-Modality Encoder Representations &mdash; HicoDR  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex/" />
    <link rel="search" title="Search" href="../../../search/" />
    <link rel="next" title="VL-BERT: Pre-training Of Generic Visuallinguistic Presentations" href="../VL-BERT/" />
    <link rel="prev" title="K-BERT: Enabling Language Representation with Knowledge Graph" href="../K-BERT/" />
   
  
  <link rel="alternate" type="application/atom+xml"  href="../../../blog/atom.xml" title="HicoDR Blog">
  
  
  <link href="True" rel="stylesheet">
  
  <style type="text/css">
    ul.ablog-archive {list-style: none; overflow: auto; margin-left: 0px}
    ul.ablog-archive li {float: left; margin-right: 5px; font-size: 80%}
    ul.postlist a {font-style: italic;}
    ul.postlist-style-disc {list-style-type: disc;}
    ul.postlist-style-none {list-style-type: none;}
    ul.postlist-style-circle {list-style-type: circle;}
  </style>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../" class="icon icon-home"> HicoDR
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">简介</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../about/">关于 HicoDR</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../first-post/">博客更新计划</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ablog/">我如何创建自己的博客</a></li>
</ul>
<p class="caption"><span class="caption-text">react-native</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../react-native/react-native1/">react-native考察：对比Flutter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../react-native/react-native2/">react-native入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../react-native/react-native3/">react-native初识:目录结构与HelloWorld</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../react-native/react-native4/">react-native初识: state 和 props</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../react-native/react-native5/">react-native初识:布局和CSS样式、第三方库的引入</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../react-native/react-native7/">react-native实战:轮播引导和登陆注册</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../react-native/react-native8/">react-native进阶:秒嘀云+Nativebase实现短信验证码登陆</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../react-native/react-native9/">react-native实战:支付宝接入app支付</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../react-native/react-native6/">react-native初识：我使用的组件</a></li>
</ul>
<p class="caption"><span class="caption-text">IOS开发</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ios/react-native10/">react-native:IOS环境搭建</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ios/iosrn/">IOS-RN踩坑记录</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ios/iap/">IOS 内购—奔溃一条龙</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ios/appstore/">IOS AppStore审核七进七出</a></li>
</ul>
<p class="caption"><span class="caption-text">机器学习-大创</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../K-BERT/">K-BERT: Enabling Language Representation with Knowledge Graph</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">LXMERT:Transformers–Learning Cross-Modality Encoder Representations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">简述</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">摘要</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">模型结构</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id4">嵌入环节</a></li>
<li class="toctree-l3"><a class="reference internal" href="#header-n25">编码器</a></li>
<li class="toctree-l3"><a class="reference internal" href="#header-n28">输出表示</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#header-n31">预训练策略</a></li>
<li class="toctree-l2"><a class="reference internal" href="#header-n49">模型微调</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id9">实验结果</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../VL-BERT/">VL-BERT: Pre-training Of Generic Visuallinguistic Presentations</a></li>
</ul>
<p class="caption"><span class="caption-text">Lua脚本</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lua/touchsprite/">触动精灵-Android自动化测试脚本</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lua/dota2rpg/">Dota2 RPG Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lua/dota2ai/">Dota2 AI 强化学习</a></li>
</ul>
<p class="caption"><span class="caption-text">杂项</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../other/bs4/">bs4爬虫实战:全家Family网站攻略</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../other/pythread/">Python多线程：Family数据批量生成</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../other/openssh/">Paramiko：Python+ssh做快乐网管</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../other/fiddler/">Fiddler:借助抓包工具写手机APP的Python脚本</a></li>
</ul>
<p class="caption"><span class="caption-text">Web 后端</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../backend/springboot1/">Springboot初识:了解Spring</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../">HicoDR</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../">Docs</a> &raquo;</li>
        
      <li>LXMERT:Transformers–Learning Cross-Modality Encoder Representations</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../_sources/docs/ml/LXMERT.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="lxmert-transformers-learning-cross-modality-encoder-representations">
<h1>LXMERT:Transformers–Learning Cross-Modality Encoder Representations<a class="headerlink" href="#lxmert-transformers-learning-cross-modality-encoder-representations" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id1">
<h2>简述<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>arXiv 1908.07490</p></li>
<li><p>官方实现 <a class="reference external" href="https://github.com/airsplay/lxmert">https://github.com/airsplay/lxmert</a></p></li>
<li><p>收录于 EMNLP 2019</p></li>
<li><p>VQA Challenge 2019 #3(Ensemble), #9(Github version)</p></li>
</ul>
</div>
<div class="section" id="id2">
<h2>摘要<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>视觉语言推理这一问题的难点主要在于不同模态之间的关系与相应语义的配对。</p>
<p>建立的框架名为“用Transformers学习跨模态编码表征”</p>
<p>由三个编码器组成：物体关系编码器、语言编码器、跨模态编码器</p>
<p>在五个不同的具有代表性的任务上进行大量的预训练：掩码语言模型、掩码物体预测（特征回归和标签分类）、跨模态匹配、图片问答。</p>
<p>对预训练的参数进行微调后可以达到比较好的效果。</p>
</div>
<div class="section" id="id3">
<h2>模型结构<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<div class="figure align-default">
<img alt="" src="../../../_images/LXMERT-1.png" />
</div>
<p><img alt="image0" src="../../../_images/LXMERT-2.png" />)</p>
<p>该跨模态模型是建立在自注意力和交叉注意力层上的（也即Transformers），如图1所示，我们的模型使用两个输入：一张图片和一个相关语句。通过精心设计的自注意力和交叉注意力层的结合，我们的模型能够学到图片、文字和跨模态的表示。</p>
<div class="section" id="id4">
<h3>嵌入环节<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p><strong>单词级别语句嵌入</strong>：词嵌入与索引嵌入相加后进行标准化。</p>
<p><strong>物体级别图片嵌入</strong>：我们把检测到的物体的特征作为图片嵌入。使用两层全连接层的感知机来学习物体的标定框和其2048维度的兴趣区域特征的联合嵌入。</p>
</div>
<div class="section" id="header-n25">
<span id="id5"></span><h3>编码器<a class="headerlink" href="#header-n25" title="Permalink to this headline">¶</a></h3>
<p><strong>单模态编码器</strong>：见图，主要由自注意力层、前馈层和全连接层组成，而在每个子层之后都加入了残差层和层标准化运算</p>
<p><strong>跨模态编码器</strong>：见图，比单模态编码器增加了交叉注意力层</p>
</div>
<div class="section" id="header-n28">
<span id="id6"></span><h3>输出表示<a class="headerlink" href="#header-n28" title="Permalink to this headline">¶</a></h3>
<p>见示意图，分别有三个输出部分，视觉和语言输出分别是由跨模态编码器生成的特征序列，而跨模态输出则和BERT的实践很类似：我们在输出的语句前增加了一个特殊的短语[CLS]，而这个短语对应的特征被用来当作跨模态输出</p>
</div>
</div>
<div class="section" id="header-n31">
<span id="id7"></span><h2>预训练策略<a class="headerlink" href="#header-n31" title="Permalink to this headline">¶</a></h2>
<p><em>在大规模数据集上进行预训练也可以视作是某种“知识嵌入”的形式的体现</em></p>
<ol class="arabic">
<li><p>掩码语言任务：与BERT基本相同，给0.15的词加上掩码并要求通过上下文的特征对掩码的内容进行预测，但该模型把从图片获得的视觉特征也作为预测掩码内容的依据之一</p></li>
<li><div class="line-block">
<div class="line">掩码物体任务：思路与上一个类似，使用全零特征作为掩码。本任务又分成两个子任务：ROI（兴趣区域）特征回归和检测标签分类。</div>
<div class="line"><em>作者提到这部分预训练的数据集由于标注不同而noisy，但实验结果表明效果其实很不错</em></div>
</div>
</li>
<li><div class="line-block">
<div class="line">跨模态任务：以0.5的概率让图片和语句乱序配对，训练一个跨模态的配对分类器（判断语句与图片是否匹配）</div>
<div class="line"><em>这里假定不同图片的描述语句与其它图片没有匹配关系</em></div>
</div>
</li>
<li><p>图片问答任务：为了扩大预训练数据集，把图片对应的问题也算作图片描述的语句。实验表明，这样使用数据集也能增强跨模态特征提取的能力</p></li>
</ol>
<p>预训练使用的数据集：</p>
<ul class="simple">
<li><p>caption: MSCOCO, Visual Genome</p></li>
<li><p>image question answering: VQA v2, GQA(balanced), VG-QA</p></li>
</ul>
<p>预训练具体过程见论文</p>
</div>
<div class="section" id="header-n49">
<span id="id8"></span><h2>模型微调<a class="headerlink" href="#header-n49" title="Permalink to this headline">¶</a></h2>
<p>在应用到具体任务时，微调过程十分迅速且抗干扰能力强，只要修改模型结构，使用数据集训练4个epoch即可</p>
</div>
<div class="section" id="id9">
<h2>实验结果<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>在VQA数据集上，该模型的所有表现都优于许多现有工作，<em>甚至在计数类问题上的精度要略高于专门使用计数模块增强的BAN</em></p></li>
<li><p>与BERT结合、仅在BUTD模型上使用跨模态编码器等方案都劣于现有模型效果</p></li>
<li><p>忽略视觉特征会降低模型效果</p></li>
<li><p>数据增强的对模型的影响效果劣于直接在大规模数据集上进行预训练</p></li>
<li><p>消融研究表明，模型结构和预训练策略对模型结果都会产生较大影响</p></li>
</ul>
</div>
</div>

  <div class="section">
  
  
  </div>

           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../VL-BERT/" class="btn btn-neutral float-right" title="VL-BERT: Pre-training Of Generic Visuallinguistic Presentations" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../K-BERT/" class="btn btn-neutral float-left" title="K-BERT: Enabling Language Representation with Knowledge Graph" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, HicoDR

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>